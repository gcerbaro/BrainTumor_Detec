{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOlwOHnc9TqDv6GBoEHRiJm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gcerbaro/BrainTumor_Detec/blob/main/model_g.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bl3yZ2wa2EpM",
        "outputId": "2a412f66-30cc-4792-b298-0a9279787644"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# =============================\n",
        "# 1. Configuração Inicial e Carregamento do Dataset\n",
        "# =============================\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "import cv2\n",
        "import os\n",
        "import shutil\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.applications import MobileNetV2\n",
        "from tensorflow.keras.layers import Dense, Dropout, Input, GlobalAveragePooling2D\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
        "from google.colab import drive\n",
        "import glob\n",
        "\n",
        "# Configurações iniciais\n",
        "drive.mount('/content/drive')\n",
        "IMG_PATH = '/content/drive/MyDrive/brain_mri_preprocessed/'\n",
        "RANDOM_SEED = 123\n",
        "IMG_SIZE = (224, 224)\n",
        "\n",
        "# Criar diretórios base\n",
        "for split in ['TRAIN', 'TEST', 'VAL']:\n",
        "    for class_name in ['YES', 'NO']:\n",
        "        os.makedirs(f'{split}/{class_name}', exist_ok=True)\n",
        "\n",
        "# Dividir os dados\n",
        "for class_name in os.listdir(IMG_PATH):\n",
        "    if not class_name.startswith('.'):\n",
        "        images = os.listdir(os.path.join(IMG_PATH, class_name))\n",
        "        for n, file_name in enumerate(images):\n",
        "            src = os.path.join(IMG_PATH, class_name, file_name)\n",
        "            if n < 5:\n",
        "                dest = f'TEST/{class_name.upper()}/{file_name}'\n",
        "            elif n < 0.8 * len(images):\n",
        "                dest = f'TRAIN/{class_name.upper()}/{file_name}'\n",
        "            else:\n",
        "                dest = f'VAL/{class_name.upper()}/{file_name}'\n",
        "            shutil.copy(src, dest)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================\n",
        "# 2. Funções de Pré-processamento\n",
        "# =============================\n",
        "def load_data(dir_path, img_size):\n",
        "    X, y = [], []\n",
        "    labels_map = {'NO': 0, 'YES': 1}\n",
        "\n",
        "    for class_name in ['NO', 'YES']:\n",
        "        class_path = os.path.join(dir_path, class_name)\n",
        "        if not os.path.exists(class_path):\n",
        "            continue\n",
        "\n",
        "        image_files = glob.glob(os.path.join(class_path, \"*.[pj][np]g\"))\n",
        "        for img_path in tqdm(image_files, desc=f\"Loading {class_name}\"):\n",
        "            img = cv2.imread(img_path)\n",
        "            if img is None:\n",
        "                continue\n",
        "\n",
        "            # Converter para 3 canais se necessário\n",
        "            if len(img.shape) == 2:\n",
        "                img = cv2.cvtColor(img, cv2.COLOR_GRAY2BGR)\n",
        "            elif img.shape[2] == 1:\n",
        "                img = cv2.cvtColor(img, cv2.COLOR_GRAY2BGR)\n",
        "\n",
        "            img = cv2.resize(img, img_size)\n",
        "            X.append(img)\n",
        "            y.append(labels_map[class_name])\n",
        "\n",
        "    return np.array(X), np.array(y)\n",
        "\n",
        "def crop_brain_region(images, img_size):\n",
        "    cropped_images = []\n",
        "    for img in tqdm(images, desc=\"Cropping images\"):\n",
        "        # Converter para escala de cinza\n",
        "        if img.shape[-1] == 3:\n",
        "            gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "        else:\n",
        "            gray = img\n",
        "\n",
        "        # Segmentação do cérebro\n",
        "        _, thresh = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
        "        contours, _ = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "\n",
        "        if contours:\n",
        "            largest_contour = max(contours, key=cv2.contourArea)\n",
        "            x, y, w, h = cv2.boundingRect(largest_contour)\n",
        "            cropped_img = img[y:y+h, x:x+w]\n",
        "            cropped_img = cv2.resize(cropped_img, img_size)\n",
        "            cropped_images.append(cropped_img)\n",
        "        else:\n",
        "            cropped_images.append(cv2.resize(img, img_size))\n",
        "\n",
        "    return np.array(cropped_images)\n",
        "\n",
        "def preprocess_mri(img):\n",
        "    \"\"\"Pré-processamento otimizado para imagens de MRI cerebral\"\"\"\n",
        "    # Garantir tipo correto\n",
        "    if img.dtype != np.uint8:\n",
        "        img = np.clip(img, 0, 255).astype(np.uint8)\n",
        "\n",
        "    # Converter para escala de cinza\n",
        "    if img.ndim == 3 and img.shape[2] == 3:\n",
        "        gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
        "    else:\n",
        "        gray = img\n",
        "\n",
        "    # 1. Redução de ruído\n",
        "    blur = cv2.bilateralFilter(gray, 9, 75, 75)\n",
        "\n",
        "    # 2. Melhorar contraste\n",
        "    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))\n",
        "    enhanced = clahe.apply(blur)\n",
        "\n",
        "    # 3. Segmentação cerebral\n",
        "    try:\n",
        "        _, mask = cv2.threshold(enhanced, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
        "        contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "\n",
        "        if contours:\n",
        "            c = max(contours, key=cv2.contourArea)\n",
        "            mask_brain = np.zeros_like(mask)\n",
        "            cv2.drawContours(mask_brain, [c], -1, 255, -1)\n",
        "            brain_only = cv2.bitwise_and(enhanced, enhanced, mask=mask_brain)\n",
        "        else:\n",
        "            brain_only = enhanced\n",
        "    except:\n",
        "        brain_only = enhanced\n",
        "\n",
        "    # 4. Redimensionar e normalizar\n",
        "    resized = cv2.resize(brain_only, IMG_SIZE)\n",
        "    normalized = resized.astype(np.float32) / 255.0\n",
        "\n",
        "    # 5. Converter para 3 canais\n",
        "    return np.stack([normalized] * 3, axis=-1)"
      ],
      "metadata": {
        "id": "rmEPnzVA2H-5"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================\n",
        "# 3. Carregamento e Processamento dos Dados\n",
        "# =============================\n",
        "# Carregar dados\n",
        "X_train, y_train = load_data('TRAIN/', IMG_SIZE)\n",
        "X_test, y_test = load_data('TEST/', IMG_SIZE)\n",
        "X_val, y_val = load_data('VAL/', IMG_SIZE)\n",
        "\n",
        "# Aplicar recorte das regiões cerebrais\n",
        "X_train_crop = crop_brain_region(X_train, IMG_SIZE)\n",
        "X_val_crop = crop_brain_region(X_val, IMG_SIZE)\n",
        "X_test_crop = crop_brain_region(X_test, IMG_SIZE)\n",
        "\n",
        "# Criar diretórios para imagens processadas\n",
        "for split in ['TRAIN_CROP', 'TEST_CROP', 'VAL_CROP']:\n",
        "    for class_name in ['YES', 'NO']:\n",
        "        os.makedirs(f'{split}/{class_name}', exist_ok=True)\n",
        "\n",
        "# Salvar imagens processadas\n",
        "def save_processed_images(images, labels, folder_name):\n",
        "    for i, (img, label) in enumerate(zip(images, labels)):\n",
        "        class_dir = 'YES' if label == 1 else 'NO'\n",
        "        filename = os.path.join(folder_name, class_dir, f\"image_{i}.jpg\")\n",
        "\n",
        "        if img.dtype != np.uint8:\n",
        "            img = (img * 255).astype(np.uint8)\n",
        "        cv2.imwrite(filename, img)\n",
        "\n",
        "save_processed_images(X_train_crop, y_train, 'TRAIN_CROP/')\n",
        "save_processed_images(X_val_crop, y_val, 'VAL_CROP/')\n",
        "save_processed_images(X_test_crop, y_test, 'TEST_CROP/')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N8Qq-7ak2KrY",
        "outputId": "ffcaf08d-a08f-44fd-97e8-7f6a23081756"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loading NO: 100%|██████████| 63/63 [00:00<00:00, 842.02it/s]\n",
            "Loading YES: 100%|██████████| 64/64 [00:00<00:00, 2839.99it/s]\n",
            "Loading NO: 100%|██████████| 5/5 [00:00<00:00, 1467.05it/s]\n",
            "Loading YES: 100%|██████████| 5/5 [00:00<00:00, 1346.31it/s]\n",
            "Loading NO: 100%|██████████| 17/17 [00:00<00:00, 2361.58it/s]\n",
            "Loading YES: 100%|██████████| 17/17 [00:00<00:00, 2580.55it/s]\n",
            "Cropping images: 100%|██████████| 127/127 [00:00<00:00, 1167.07it/s]\n",
            "Cropping images: 100%|██████████| 34/34 [00:00<00:00, 1357.44it/s]\n",
            "Cropping images: 100%|██████████| 10/10 [00:00<00:00, 1399.45it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================\n",
        "# 4. Data Augmentation e Modelo\n",
        "# =============================\n",
        "# Data generators\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rotation_range=15,\n",
        "    width_shift_range=0.1,\n",
        "    height_shift_range=0.1,\n",
        "    shear_range=0.1,\n",
        "    zoom_range=0.1,\n",
        "    horizontal_flip=True,\n",
        "    brightness_range=[0.9, 1.1],\n",
        "    fill_mode='nearest',\n",
        "    preprocessing_function=preprocess_mri\n",
        ")\n",
        "\n",
        "val_datagen = ImageDataGenerator(preprocessing_function=preprocess_mri)\n",
        "\n",
        "BATCH_SIZE = 32\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    'TRAIN_CROP/',\n",
        "    target_size=IMG_SIZE,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    class_mode='binary',\n",
        "    seed=RANDOM_SEED\n",
        ")\n",
        "\n",
        "validation_generator = val_datagen.flow_from_directory(\n",
        "    'VAL_CROP/',\n",
        "    target_size=IMG_SIZE,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    class_mode='binary',\n",
        "    seed=RANDOM_SEED\n",
        ")\n",
        "\n",
        "# Modelo otimizado\n",
        "def create_model():\n",
        "    base_model = MobileNetV2(\n",
        "        include_top=False,\n",
        "        weights='imagenet',\n",
        "        input_shape=(*IMG_SIZE, 3)\n",
        "    )\n",
        "    base_model.trainable = False\n",
        "\n",
        "    inputs = Input(shape=(*IMG_SIZE, 3))\n",
        "    x = base_model(inputs, training=False)\n",
        "    x = GlobalAveragePooling2D()(x)\n",
        "    x = Dropout(0.5)(x)\n",
        "    x = Dense(128, activation='relu')(x)\n",
        "    x = Dropout(0.3)(x)\n",
        "    outputs = Dense(1, activation='sigmoid')(x)\n",
        "\n",
        "    model = Model(inputs, outputs)\n",
        "    model.compile(\n",
        "        optimizer=Adam(learning_rate=1e-3),\n",
        "        loss='binary_crossentropy',\n",
        "        metrics=['accuracy', 'precision', 'recall']\n",
        "    )\n",
        "    return model\n",
        "\n",
        "model = create_model()\n",
        "\n",
        "# Callbacks\n",
        "checkpoint_path = \"/content/drive/MyDrive/best_brain_mri_model.h5\"\n",
        "callbacks = [\n",
        "    EarlyStopping(monitor='val_accuracy', patience=15, restore_best_weights=True, verbose=1),\n",
        "    ModelCheckpoint(checkpoint_path, monitor='val_accuracy', save_best_only=True, verbose=1),\n",
        "    ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5, min_lr=1e-7, verbose=1)\n",
        "]\n",
        "\n",
        "# Treinamento\n",
        "steps_per_epoch = train_generator.samples // BATCH_SIZE\n",
        "validation_steps = validation_generator.samples // BATCH_SIZE\n",
        "\n",
        "print(\"=== FASE 1: TREINAMENTO BASE ===\")\n",
        "history1 = model.fit(\n",
        "    train_generator,\n",
        "    steps_per_epoch=steps_per_epoch,\n",
        "    epochs=20,\n",
        "    validation_data=validation_generator,\n",
        "    validation_steps=validation_steps,\n",
        "    callbacks=callbacks,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "print(\"=== FASE 2: FINE-TUNING ===\")\n",
        "# Descongelar parcialmente a base\n",
        "for layer in model.layers[1].layers[-50:]:\n",
        "    layer.trainable = True\n",
        "\n",
        "model.compile(\n",
        "    optimizer=Adam(learning_rate=1e-4),\n",
        "    loss='binary_crossentropy',\n",
        "    metrics=['accuracy', 'precision', 'recall']\n",
        ")\n",
        "\n",
        "history2 = model.fit(\n",
        "    train_generator,\n",
        "    steps_per_epoch=steps_per_epoch,\n",
        "    epochs=10,\n",
        "    validation_data=validation_generator,\n",
        "    validation_steps=validation_steps,\n",
        "    callbacks=callbacks,\n",
        "    verbose=1\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ds5abXdg2MpQ",
        "outputId": "559c1c38-7533-4439-f54a-d8665e1b51a3"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 127 images belonging to 2 classes.\n",
            "Found 34 images belonging to 2 classes.\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/mobilenet_v2/mobilenet_v2_weights_tf_dim_ordering_tf_kernels_1.0_224_no_top.h5\n",
            "\u001b[1m9406464/9406464\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 0us/step\n",
            "=== FASE 1: TREINAMENTO BASE ===\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.5330 - loss: 0.8833 - precision: 0.5523 - recall: 0.6503\n",
            "Epoch 1: val_accuracy improved from -inf to 0.71875, saving model to /content/drive/MyDrive/best_brain_mri_model.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 6s/step - accuracy: 0.5261 - loss: 0.8906 - precision: 0.5506 - recall: 0.6054 - val_accuracy: 0.7188 - val_loss: 0.6248 - val_precision: 0.6250 - val_recall: 1.0000 - learning_rate: 0.0010\n",
            "Epoch 2/20\n",
            "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 1s/step - accuracy: 0.5312 - loss: 0.7984 - precision: 0.4444 - recall: 0.6154"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/trainers/epoch_iterator.py:116: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
            "  self._interrupted_warning()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 2: val_accuracy did not improve from 0.71875\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 776ms/step - accuracy: 0.5312 - loss: 0.7984 - precision: 0.4444 - recall: 0.6154 - val_accuracy: 0.6562 - val_loss: 0.6346 - val_precision: 0.6000 - val_recall: 0.9375 - learning_rate: 0.0010\n",
            "Epoch 3/20\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.3884 - loss: 1.0252 - precision: 0.4042 - recall: 0.5629\n",
            "Epoch 3: val_accuracy did not improve from 0.71875\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 7s/step - accuracy: 0.3834 - loss: 1.0224 - precision: 0.3969 - recall: 0.5585 - val_accuracy: 0.6875 - val_loss: 0.6147 - val_precision: 0.8000 - val_recall: 0.5000 - learning_rate: 0.0010\n",
            "Epoch 4/20\n",
            "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 2s/step - accuracy: 0.5625 - loss: 0.7226 - precision: 0.7143 - recall: 0.5000\n",
            "Epoch 4: val_accuracy did not improve from 0.71875\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 924ms/step - accuracy: 0.5625 - loss: 0.7226 - precision: 0.7143 - recall: 0.5000 - val_accuracy: 0.7188 - val_loss: 0.5795 - val_precision: 0.8182 - val_recall: 0.5625 - learning_rate: 0.0010\n",
            "Epoch 5/20\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3s/step - accuracy: 0.4152 - loss: 0.9814 - precision: 0.4158 - recall: 0.3285\n",
            "Epoch 5: val_accuracy did not improve from 0.71875\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 3s/step - accuracy: 0.4219 - loss: 0.9680 - precision: 0.4119 - recall: 0.3352 - val_accuracy: 0.7188 - val_loss: 0.5782 - val_precision: 0.8000 - val_recall: 0.5333 - learning_rate: 0.0010\n",
            "Epoch 6/20\n",
            "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 1s/step - accuracy: 0.4375 - loss: 0.8405 - precision: 0.5455 - recall: 0.3158\n",
            "Epoch 6: val_accuracy did not improve from 0.71875\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 734ms/step - accuracy: 0.4375 - loss: 0.8405 - precision: 0.5455 - recall: 0.3158 - val_accuracy: 0.6875 - val_loss: 0.5935 - val_precision: 0.8000 - val_recall: 0.5000 - learning_rate: 0.0010\n",
            "Epoch 7/20\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.5713 - loss: 0.7711 - precision: 0.6148 - recall: 0.4796\n",
            "Epoch 7: val_accuracy did not improve from 0.71875\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 2s/step - accuracy: 0.5600 - loss: 0.7778 - precision: 0.5920 - recall: 0.4767 - val_accuracy: 0.6875 - val_loss: 0.6356 - val_precision: 0.6667 - val_recall: 0.8235 - learning_rate: 0.0010\n",
            "Epoch 8/20\n",
            "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 1s/step - accuracy: 0.5625 - loss: 0.8087 - precision: 0.6000 - recall: 0.5294\n",
            "Epoch 8: val_accuracy improved from 0.71875 to 0.75000, saving model to /content/drive/MyDrive/best_brain_mri_model.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3s/step - accuracy: 0.5625 - loss: 0.8087 - precision: 0.6000 - recall: 0.5294 - val_accuracy: 0.7500 - val_loss: 0.6300 - val_precision: 0.6818 - val_recall: 0.9375 - learning_rate: 0.0010\n",
            "Epoch 9/20\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.6010 - loss: 0.7426 - precision: 0.5537 - recall: 0.7586\n",
            "Epoch 9: val_accuracy did not improve from 0.75000\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2s/step - accuracy: 0.6008 - loss: 0.7378 - precision: 0.5593 - recall: 0.7498 - val_accuracy: 0.6875 - val_loss: 0.6537 - val_precision: 0.6522 - val_recall: 0.8824 - learning_rate: 0.0010\n",
            "Epoch 10/20\n",
            "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 2s/step - accuracy: 0.5312 - loss: 0.7209 - precision: 0.5556 - recall: 0.5882\n",
            "Epoch 10: val_accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 10: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2s/step - accuracy: 0.5312 - loss: 0.7209 - precision: 0.5556 - recall: 0.5882 - val_accuracy: 0.7188 - val_loss: 0.6433 - val_precision: 0.6667 - val_recall: 0.8750 - learning_rate: 0.0010\n",
            "Epoch 11/20\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.6166 - loss: 0.6597 - precision: 0.6310 - recall: 0.5920\n",
            "Epoch 11: val_accuracy did not improve from 0.75000\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2s/step - accuracy: 0.6045 - loss: 0.6631 - precision: 0.6101 - recall: 0.5718 - val_accuracy: 0.7188 - val_loss: 0.6440 - val_precision: 0.6667 - val_recall: 0.8750 - learning_rate: 5.0000e-04\n",
            "Epoch 12/20\n",
            "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 1s/step - accuracy: 0.4375 - loss: 0.7455 - precision: 0.5385 - recall: 0.3684\n",
            "Epoch 12: val_accuracy did not improve from 0.75000\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1s/step - accuracy: 0.4375 - loss: 0.7455 - precision: 0.5385 - recall: 0.3684 - val_accuracy: 0.7188 - val_loss: 0.6428 - val_precision: 0.6667 - val_recall: 0.8750 - learning_rate: 5.0000e-04\n",
            "Epoch 13/20\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.5941 - loss: 0.6919 - precision: 0.4909 - recall: 0.4466\n",
            "Epoch 13: val_accuracy did not improve from 0.75000\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2s/step - accuracy: 0.5982 - loss: 0.6991 - precision: 0.5226 - recall: 0.4516 - val_accuracy: 0.7188 - val_loss: 0.6245 - val_precision: 0.6500 - val_recall: 0.8667 - learning_rate: 5.0000e-04\n",
            "Epoch 14/20\n",
            "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 1s/step - accuracy: 0.4062 - loss: 0.8300 - precision: 0.5000 - recall: 0.2632\n",
            "Epoch 14: val_accuracy did not improve from 0.75000\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 773ms/step - accuracy: 0.4062 - loss: 0.8300 - precision: 0.5000 - recall: 0.2632 - val_accuracy: 0.7500 - val_loss: 0.6353 - val_precision: 0.7000 - val_recall: 0.8750 - learning_rate: 5.0000e-04\n",
            "Epoch 15/20\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.5748 - loss: 0.7497 - precision: 0.6062 - recall: 0.4585\n",
            "Epoch 15: val_accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 15: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 3s/step - accuracy: 0.5653 - loss: 0.7543 - precision: 0.5949 - recall: 0.4613 - val_accuracy: 0.6875 - val_loss: 0.6823 - val_precision: 0.6190 - val_recall: 0.8667 - learning_rate: 5.0000e-04\n",
            "Epoch 16/20\n",
            "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 1s/step - accuracy: 0.5625 - loss: 0.7341 - precision: 0.5333 - recall: 0.5333\n",
            "Epoch 16: val_accuracy did not improve from 0.75000\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 747ms/step - accuracy: 0.5625 - loss: 0.7341 - precision: 0.5333 - recall: 0.5333 - val_accuracy: 0.6875 - val_loss: 0.6869 - val_precision: 0.6190 - val_recall: 0.8667 - learning_rate: 2.5000e-04\n",
            "Epoch 17/20\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.5243 - loss: 0.7329 - precision: 0.5597 - recall: 0.6696\n",
            "Epoch 17: val_accuracy did not improve from 0.75000\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4s/step - accuracy: 0.5286 - loss: 0.7321 - precision: 0.5553 - recall: 0.6655 - val_accuracy: 0.7500 - val_loss: 0.6505 - val_precision: 0.7143 - val_recall: 0.8824 - learning_rate: 2.5000e-04\n",
            "Epoch 18/20\n",
            "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 1s/step - accuracy: 0.5806 - loss: 0.7343 - precision: 0.5625 - recall: 0.6000\n",
            "Epoch 18: val_accuracy did not improve from 0.75000\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 744ms/step - accuracy: 0.5806 - loss: 0.7343 - precision: 0.5625 - recall: 0.6000 - val_accuracy: 0.6875 - val_loss: 0.6679 - val_precision: 0.6522 - val_recall: 0.8824 - learning_rate: 2.5000e-04\n",
            "Epoch 19/20\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.4740 - loss: 0.7216 - precision: 0.4800 - recall: 0.5236\n",
            "Epoch 19: val_accuracy did not improve from 0.75000\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 5s/step - accuracy: 0.4870 - loss: 0.7178 - precision: 0.4964 - recall: 0.5427 - val_accuracy: 0.6875 - val_loss: 0.6890 - val_precision: 0.6190 - val_recall: 0.8667 - learning_rate: 2.5000e-04\n",
            "Epoch 20/20\n",
            "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 2s/step - accuracy: 0.5938 - loss: 0.6930 - precision: 0.5263 - recall: 0.7143\n",
            "Epoch 20: val_accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 20: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1s/step - accuracy: 0.5938 - loss: 0.6930 - precision: 0.5263 - recall: 0.7143 - val_accuracy: 0.7188 - val_loss: 0.6415 - val_precision: 0.6667 - val_recall: 0.8750 - learning_rate: 2.5000e-04\n",
            "Restoring model weights from the end of the best epoch: 8.\n",
            "=== FASE 2: FINE-TUNING ===\n",
            "Epoch 1/10\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3s/step - accuracy: 0.4895 - loss: 0.7773 - precision: 0.4900 - recall: 0.6048\n",
            "Epoch 1: val_accuracy did not improve from 0.75000\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 6s/step - accuracy: 0.4882 - loss: 0.7757 - precision: 0.4882 - recall: 0.6026 - val_accuracy: 0.7188 - val_loss: 0.5940 - val_precision: 0.7222 - val_recall: 0.7647 - learning_rate: 1.0000e-04\n",
            "Epoch 2/10\n",
            "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m5s\u001b[0m 3s/step - accuracy: 0.6875 - loss: 0.6282 - precision: 0.7059 - recall: 0.7059\n",
            "Epoch 2: val_accuracy did not improve from 0.75000\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1s/step - accuracy: 0.6875 - loss: 0.6282 - precision: 0.7059 - recall: 0.7059 - val_accuracy: 0.6875 - val_loss: 0.6210 - val_precision: 0.6667 - val_recall: 0.7500 - learning_rate: 1.0000e-04\n",
            "Epoch 3/10\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3s/step - accuracy: 0.5417 - loss: 0.7136 - precision: 0.5738 - recall: 0.5796\n",
            "Epoch 3: val_accuracy did not improve from 0.75000\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 3s/step - accuracy: 0.5469 - loss: 0.7091 - precision: 0.5793 - recall: 0.5720 - val_accuracy: 0.7188 - val_loss: 0.6056 - val_precision: 0.7059 - val_recall: 0.7500 - learning_rate: 1.0000e-04\n",
            "Epoch 4/10\n",
            "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 3s/step - accuracy: 0.4194 - loss: 0.7852 - precision: 0.2727 - recall: 0.2308\n",
            "Epoch 4: val_accuracy improved from 0.75000 to 0.78125, saving model to /content/drive/MyDrive/best_brain_mri_model.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2s/step - accuracy: 0.4194 - loss: 0.7852 - precision: 0.2727 - recall: 0.2308 - val_accuracy: 0.7812 - val_loss: 0.5198 - val_precision: 0.8125 - val_recall: 0.7647 - learning_rate: 1.0000e-04\n",
            "Epoch 5/10\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3s/step - accuracy: 0.5660 - loss: 0.6989 - precision: 0.7707 - recall: 0.3659\n",
            "Epoch 5: val_accuracy did not improve from 0.78125\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 8s/step - accuracy: 0.5755 - loss: 0.6967 - precision: 0.7632 - recall: 0.3724 - val_accuracy: 0.7812 - val_loss: 0.5771 - val_precision: 0.7647 - val_recall: 0.8125 - learning_rate: 1.0000e-04\n",
            "Epoch 6/10\n",
            "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 2s/step - accuracy: 0.4516 - loss: 0.6880 - precision: 0.3333 - recall: 0.3077\n",
            "Epoch 6: val_accuracy did not improve from 0.78125\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1s/step - accuracy: 0.4516 - loss: 0.6880 - precision: 0.3333 - recall: 0.3077 - val_accuracy: 0.7500 - val_loss: 0.6063 - val_precision: 0.7647 - val_recall: 0.7647 - learning_rate: 1.0000e-04\n",
            "Epoch 7/10\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3s/step - accuracy: 0.5253 - loss: 0.7096 - precision: 0.5083 - recall: 0.6165\n",
            "Epoch 7: val_accuracy did not improve from 0.78125\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 8s/step - accuracy: 0.5282 - loss: 0.7061 - precision: 0.5128 - recall: 0.6220 - val_accuracy: 0.7500 - val_loss: 0.5696 - val_precision: 0.7500 - val_recall: 0.7500 - learning_rate: 1.0000e-04\n",
            "Epoch 8/10\n",
            "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 2s/step - accuracy: 0.6562 - loss: 0.6943 - precision: 0.7143 - recall: 0.5882\n",
            "Epoch 8: val_accuracy did not improve from 0.78125\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 752ms/step - accuracy: 0.6562 - loss: 0.6943 - precision: 0.7143 - recall: 0.5882 - val_accuracy: 0.6875 - val_loss: 0.5950 - val_precision: 0.7143 - val_recall: 0.6250 - learning_rate: 1.0000e-04\n",
            "Epoch 9/10\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3s/step - accuracy: 0.5471 - loss: 0.6723 - precision: 0.5551 - recall: 0.5069\n",
            "Epoch 9: val_accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 9: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 4s/step - accuracy: 0.5551 - loss: 0.6724 - precision: 0.5622 - recall: 0.5260 - val_accuracy: 0.6875 - val_loss: 0.5878 - val_precision: 0.7333 - val_recall: 0.6471 - learning_rate: 1.0000e-04\n",
            "Epoch 10/10\n",
            "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 2s/step - accuracy: 0.5000 - loss: 0.7472 - precision: 0.5000 - recall: 0.6875\n",
            "Epoch 10: val_accuracy did not improve from 0.78125\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 739ms/step - accuracy: 0.5000 - loss: 0.7472 - precision: 0.5000 - recall: 0.6875 - val_accuracy: 0.7500 - val_loss: 0.4869 - val_precision: 0.7857 - val_recall: 0.6875 - learning_rate: 5.0000e-05\n",
            "Restoring model weights from the end of the best epoch: 4.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================\n",
        "# 5. Avaliação Final\n",
        "# =============================\n",
        "print(\"=== AVALIAÇÃO FINAL ===\")\n",
        "validation_generator.reset()\n",
        "test_loss, test_accuracy, test_precision, test_recall = model.evaluate(\n",
        "    validation_generator,\n",
        "    steps=validation_generator.samples // BATCH_SIZE\n",
        ")\n",
        "\n",
        "print(f\"\\n=== RESULTADOS FINAIS ===\")\n",
        "print(f\"Accuracy: {test_accuracy:.4f}\")\n",
        "print(f\"Precision: {test_precision:.4f}\")\n",
        "print(f\"Recall: {test_recall:.4f}\")\n",
        "\n",
        "# Salvar modelo final\n",
        "final_model_path = \"/content/drive/MyDrive/final_brain_mri_model.h5\"\n",
        "model.save(final_model_path)\n",
        "print(f\"\\nModelo salvo em: {final_model_path}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nfQFhFjh2PQp",
        "outputId": "6b5f86b9-0882-4c0f-8f17-99b3e15c9e0c"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== AVALIAÇÃO FINAL ===\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.7812 - loss: 0.5918 - precision: 0.7647 - recall: 0.8125\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== RESULTADOS FINAIS ===\n",
            "Accuracy: 0.7812\n",
            "Precision: 0.7647\n",
            "Recall: 0.8125\n",
            "\n",
            "Modelo salvo em: /content/drive/MyDrive/final_brain_mri_model.h5\n"
          ]
        }
      ]
    }
  ]
}